{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b29d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf12422",
   "metadata": {},
   "source": [
    "Read financials news dataset and merge into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f73726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add company label in dataset\n",
    "years = ['2021', '2022', '2023']\n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "companies = ['AAPL', 'AMZN', 'MSFT', 'META', 'TSLA']\n",
    "\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        for company in companies:\n",
    "            df_fn = pd.read_csv(f'data/{year}/{quarter}_News/{company}_{year}{quarter}_Financial_News.csv')\n",
    "            df_fn['company'] = company\n",
    "            df_fn.to_csv(f'data/{year}/{quarter}_News/{company}_{year}{quarter}_Financial_News.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fb0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge csv files and group it into quarter\n",
    "\n",
    "for i in years:\n",
    "    for j in quarters:\n",
    "        files = [\n",
    "            f'data/{i}/{j}_News/AAPL_{i}{j}_Financial_News.csv', \n",
    "            f'data/{i}/{j}_News/AMZN_{i}{j}_Financial_News.csv',\n",
    "            f'data/{i}/{j}_News/TSLA_{i}{j}_Financial_News.csv',\n",
    "            f'data/{i}/{j}_News/MSFT_{i}{j}_Financial_News.csv',\n",
    "            f'data/{i}/{j}_News/META_{i}{j}_Financial_News.csv'\n",
    "        ]\n",
    "        df_fn = pd.concat( \n",
    "            map(pd.read_csv, files), ignore_index=True)\n",
    "        df_fn.to_csv(f'Financial News/{i}_{j}_Financial_News.csv', index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c899e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge and group according to years\n",
    "for i in years:\n",
    "    files = [\n",
    "            f'Financial News/{i}_Q1_Financial_News.csv', \n",
    "            f'Financial News/{i}_Q2_Financial_News.csv',\n",
    "            f'Financial News/{i}_Q3_Financial_News.csv',\n",
    "            f'Financial News/{i}_Q4_Financial_News.csv'\n",
    "        ]\n",
    "    df_fn = pd.concat( \n",
    "        map(pd.read_csv, files), ignore_index=True)\n",
    "    df_fn.to_csv(f'Financial News/{i}_Financial_News.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2080dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all csv files into one csv file\n",
    "files = [\n",
    "            'Financial News/2021_Financial_News.csv', \n",
    "            'Financial News/2022_Financial_News.csv',\n",
    "            'Financial News/2023_Financial_News.csv',\n",
    "        ]\n",
    "df_fn = pd.concat( \n",
    "        map(pd.read_csv, files), ignore_index=True)\n",
    "df_fn.to_csv('FinancialNews.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee93c8",
   "metadata": {},
   "source": [
    "Read financial historical stock data and merge into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffb3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add company label in dataset\n",
    "for company in companies:\n",
    "    df = pd.read_csv(f'Historical stock prices/{company}_historical_data.csv')\n",
    "    df['company'] = company\n",
    "    df.to_csv(f'Historical stock prices/{company}_historical_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0d8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Historical stock prices/AAPL_historical_data.csv', \n",
    "         'Historical stock prices/AMZN_historical_data.csv',\n",
    "         'Historical stock prices/TSLA_historical_data.csv',\n",
    "         'Historical stock prices/MSFT_historical_data.csv',\n",
    "         'Historical stock prices/META_historical_data.csv'\n",
    "        ]\n",
    "df_sp = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "df_sp.to_csv('Stock_Prices.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64020807",
   "metadata": {},
   "source": [
    "## Data Cleaning of Financial News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3beb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4622 entries, 0 to 4621\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      4622 non-null   int64  \n",
      " 1   Unnamed: 0.1    4622 non-null   int64  \n",
      " 2   title           4622 non-null   object \n",
      " 3   description     4622 non-null   object \n",
      " 4   published date  4622 non-null   object \n",
      " 5   url             4622 non-null   object \n",
      " 6   publisher       4622 non-null   object \n",
      " 7   company         4622 non-null   object \n",
      " 8   Unnamed: 0.1.1  985 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 325.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_fn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ebd1fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>published date</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>company</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple (AAPL) to Report Q1 Earnings: What's in ...</td>\n",
       "      <td>Apple (AAPL) to Report Q1 Earnings: What's in ...</td>\n",
       "      <td>Fri, 22 Jan 2021 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiS2h0d...</td>\n",
       "      <td>{'href': 'https://finance.yahoo.com', 'title':...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>How to Trade Apple (AAPL) in the First Half of...</td>\n",
       "      <td>How to Trade Apple (AAPL) in the First Half of...</td>\n",
       "      <td>Thu, 07 Jan 2021 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiUWh0d...</td>\n",
       "      <td>{'href': 'https://www.investopedia.com', 'titl...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>What Facebook (FB), Twitter (TWTR), Apple (AAP...</td>\n",
       "      <td>What Facebook (FB), Twitter (TWTR), Apple (AAP...</td>\n",
       "      <td>Mon, 08 Feb 2021 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMidGh0d...</td>\n",
       "      <td>{'href': 'https://www.bloomberg.com', 'title':...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>AAPL After Hours: Share Price Slides On Tech W...</td>\n",
       "      <td>AAPL After Hours: Share Price Slides On Tech W...</td>\n",
       "      <td>Wed, 24 Mar 2021 07:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSmh0d...</td>\n",
       "      <td>{'href': 'https://www.thestreet.com', 'title':...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple reports blowout quarter, booking more th...</td>\n",
       "      <td>Apple reports blowout quarter, booking more th...</td>\n",
       "      <td>Wed, 27 Jan 2021 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiQGh0d...</td>\n",
       "      <td>{'href': 'https://www.cnbc.com', 'title': 'CNBC'}</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             2   \n",
       "3           3             3   \n",
       "4           4             4   \n",
       "\n",
       "                                               title  \\\n",
       "0  Apple (AAPL) to Report Q1 Earnings: What's in ...   \n",
       "1  How to Trade Apple (AAPL) in the First Half of...   \n",
       "2  What Facebook (FB), Twitter (TWTR), Apple (AAP...   \n",
       "3  AAPL After Hours: Share Price Slides On Tech W...   \n",
       "4  Apple reports blowout quarter, booking more th...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Apple (AAPL) to Report Q1 Earnings: What's in ...   \n",
       "1  How to Trade Apple (AAPL) in the First Half of...   \n",
       "2  What Facebook (FB), Twitter (TWTR), Apple (AAP...   \n",
       "3  AAPL After Hours: Share Price Slides On Tech W...   \n",
       "4  Apple reports blowout quarter, booking more th...   \n",
       "\n",
       "                  published date  \\\n",
       "0  Fri, 22 Jan 2021 08:00:00 GMT   \n",
       "1  Thu, 07 Jan 2021 08:00:00 GMT   \n",
       "2  Mon, 08 Feb 2021 08:00:00 GMT   \n",
       "3  Wed, 24 Mar 2021 07:00:00 GMT   \n",
       "4  Wed, 27 Jan 2021 08:00:00 GMT   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://news.google.com/rss/articles/CBMiS2h0d...   \n",
       "1  https://news.google.com/rss/articles/CBMiUWh0d...   \n",
       "2  https://news.google.com/rss/articles/CBMidGh0d...   \n",
       "3  https://news.google.com/rss/articles/CBMiSmh0d...   \n",
       "4  https://news.google.com/rss/articles/CBMiQGh0d...   \n",
       "\n",
       "                                           publisher company  Unnamed: 0.1.1  \n",
       "0  {'href': 'https://finance.yahoo.com', 'title':...    AAPL             NaN  \n",
       "1  {'href': 'https://www.investopedia.com', 'titl...    AAPL             NaN  \n",
       "2  {'href': 'https://www.bloomberg.com', 'title':...    AAPL             NaN  \n",
       "3  {'href': 'https://www.thestreet.com', 'title':...    AAPL             NaN  \n",
       "4  {'href': 'https://www.cnbc.com', 'title': 'CNBC'}    AAPL             NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c562292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>published date</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>company</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>Meta Quest 3: The Holiday Gift That Transforms...</td>\n",
       "      <td>Meta Quest 3: The Holiday Gift That Transforms...</td>\n",
       "      <td>Wed, 29 Nov 2023 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiVmh0d...</td>\n",
       "      <td>{'href': 'https://about.fb.com', 'title': 'Meta'}</td>\n",
       "      <td>META</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>noyb files GDPR complaint against Meta over “P...</td>\n",
       "      <td>noyb files GDPR complaint against Meta over “P...</td>\n",
       "      <td>Tue, 28 Nov 2023 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSmh0d...</td>\n",
       "      <td>{'href': 'https://noyb.eu', 'title': 'NOYB'}</td>\n",
       "      <td>META</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>Two years later, Facebook's rebrand as Meta lo...</td>\n",
       "      <td>Two years later, Facebook's rebrand as Meta lo...</td>\n",
       "      <td>Sat, 28 Oct 2023 07:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiS2h0d...</td>\n",
       "      <td>{'href': 'https://www.fastcompany.com', 'title...</td>\n",
       "      <td>META</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>Meta smart glasses—large language models and t...</td>\n",
       "      <td>Meta smart glasses—large language models and t...</td>\n",
       "      <td>Mon, 04 Dec 2023 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiMmh0d...</td>\n",
       "      <td>{'href': 'https://www.nature.com', 'title': 'N...</td>\n",
       "      <td>META</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>Meta-reinforcement learning via orbitofrontal ...</td>\n",
       "      <td>Meta-reinforcement learning via orbitofrontal ...</td>\n",
       "      <td>Mon, 13 Nov 2023 08:00:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiMmh0d...</td>\n",
       "      <td>{'href': 'https://www.nature.com', 'title': 'N...</td>\n",
       "      <td>META</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  \\\n",
       "4617          84            84   \n",
       "4618          85            85   \n",
       "4619          86            86   \n",
       "4620          87            87   \n",
       "4621          88            88   \n",
       "\n",
       "                                                  title  \\\n",
       "4617  Meta Quest 3: The Holiday Gift That Transforms...   \n",
       "4618  noyb files GDPR complaint against Meta over “P...   \n",
       "4619  Two years later, Facebook's rebrand as Meta lo...   \n",
       "4620  Meta smart glasses—large language models and t...   \n",
       "4621  Meta-reinforcement learning via orbitofrontal ...   \n",
       "\n",
       "                                            description  \\\n",
       "4617  Meta Quest 3: The Holiday Gift That Transforms...   \n",
       "4618  noyb files GDPR complaint against Meta over “P...   \n",
       "4619  Two years later, Facebook's rebrand as Meta lo...   \n",
       "4620  Meta smart glasses—large language models and t...   \n",
       "4621  Meta-reinforcement learning via orbitofrontal ...   \n",
       "\n",
       "                     published date  \\\n",
       "4617  Wed, 29 Nov 2023 08:00:00 GMT   \n",
       "4618  Tue, 28 Nov 2023 08:00:00 GMT   \n",
       "4619  Sat, 28 Oct 2023 07:00:00 GMT   \n",
       "4620  Mon, 04 Dec 2023 08:00:00 GMT   \n",
       "4621  Mon, 13 Nov 2023 08:00:00 GMT   \n",
       "\n",
       "                                                    url  \\\n",
       "4617  https://news.google.com/rss/articles/CBMiVmh0d...   \n",
       "4618  https://news.google.com/rss/articles/CBMiSmh0d...   \n",
       "4619  https://news.google.com/rss/articles/CBMiS2h0d...   \n",
       "4620  https://news.google.com/rss/articles/CBMiMmh0d...   \n",
       "4621  https://news.google.com/rss/articles/CBMiMmh0d...   \n",
       "\n",
       "                                              publisher company  \\\n",
       "4617  {'href': 'https://about.fb.com', 'title': 'Meta'}    META   \n",
       "4618       {'href': 'https://noyb.eu', 'title': 'NOYB'}    META   \n",
       "4619  {'href': 'https://www.fastcompany.com', 'title...    META   \n",
       "4620  {'href': 'https://www.nature.com', 'title': 'N...    META   \n",
       "4621  {'href': 'https://www.nature.com', 'title': 'N...    META   \n",
       "\n",
       "      Unnamed: 0.1.1  \n",
       "4617             NaN  \n",
       "4618             NaN  \n",
       "4619             NaN  \n",
       "4620             NaN  \n",
       "4621             NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fn.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b21051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#removed unwanted column\n",
    "df_fn = df_fn.drop(['Unnamed: 0', 'Unnamed: 0.1', 'description', 'Unnamed: 0.1.1'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d91a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there is any duplication\n",
    "df_fn.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ccec366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicated value\n",
    "df_fn.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebea4de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             0\n",
       "published date    0\n",
       "url               0\n",
       "publisher         0\n",
       "company           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there is any missing value\n",
    "df_fn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522b110d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             0\n",
       "published date    0\n",
       "url               0\n",
       "publisher         0\n",
       "company           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "676f6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns name of financial news csv file\n",
    "df_fn = df_fn.iloc[:,[1, -1, 0, 3, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a099ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#format date\n",
    "from datetime import datetime\n",
    "\n",
    "# covert to datetime\n",
    "df_fn['published date'] = pd.to_datetime(df_fn['published date'])\n",
    "\n",
    "# date in MM-DD-YYYY format\n",
    "df_fn['published date'] = df_fn['published date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1064a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the publisher instead of url\n",
    "import ast\n",
    "\n",
    "df_fn['publisher'] = pd.Series(df_fn['publisher'], dtype=\"string\")\n",
    "\n",
    "def extract_title(dict_string):\n",
    "    try:\n",
    "        # Convert string to dictionary\n",
    "        dict_obj = ast.literal_eval(dict_string)\n",
    "        \n",
    "        # Extract the title\n",
    "        return dict_obj.get('title')\n",
    "    \n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "    \n",
    "df_fn['publisher'] = df_fn['publisher'].apply(extract_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e756f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn.to_csv('FinancialNews.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a6ab2f",
   "metadata": {},
   "source": [
    "## Data Cleaning for Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4cfc912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3765 entries, 0 to 3764\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       3765 non-null   object \n",
      " 1   Open       3765 non-null   float64\n",
      " 2   High       3765 non-null   float64\n",
      " 3   Low        3765 non-null   float64\n",
      " 4   Close      3765 non-null   float64\n",
      " 5   Adj Close  3765 non-null   float64\n",
      " 6   Volume     3765 non-null   int64  \n",
      " 7   company    3765 non-null   object \n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 235.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fa0f015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04T00:00:00.000</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>133.610001</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>126.830078</td>\n",
       "      <td>143301900</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05T00:00:00.000</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>128.398163</td>\n",
       "      <td>97664900</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06T00:00:00.000</td>\n",
       "      <td>127.720001</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>124.076096</td>\n",
       "      <td>155088000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07T00:00:00.000</td>\n",
       "      <td>128.360001</td>\n",
       "      <td>131.630005</td>\n",
       "      <td>127.860001</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>128.309982</td>\n",
       "      <td>109578200</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08T00:00:00.000</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>129.417465</td>\n",
       "      <td>105158200</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date        Open        High         Low       Close  \\\n",
       "0  2021-01-04T00:00:00.000  133.520004  133.610001  126.760002  129.410004   \n",
       "1  2021-01-05T00:00:00.000  128.889999  131.740005  128.429993  131.009995   \n",
       "2  2021-01-06T00:00:00.000  127.720001  131.050003  126.379997  126.599998   \n",
       "3  2021-01-07T00:00:00.000  128.360001  131.630005  127.860001  130.919998   \n",
       "4  2021-01-08T00:00:00.000  132.429993  132.630005  130.229996  132.050003   \n",
       "\n",
       "    Adj Close     Volume company  \n",
       "0  126.830078  143301900    AAPL  \n",
       "1  128.398163   97664900    AAPL  \n",
       "2  124.076096  155088000    AAPL  \n",
       "3  128.309982  109578200    AAPL  \n",
       "4  129.417465  105158200    AAPL  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58942bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>2023-12-22T00:00:00.000</td>\n",
       "      <td>355.579987</td>\n",
       "      <td>357.200012</td>\n",
       "      <td>351.220001</td>\n",
       "      <td>353.390015</td>\n",
       "      <td>353.015472</td>\n",
       "      <td>11764200</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>2023-12-26T00:00:00.000</td>\n",
       "      <td>354.989990</td>\n",
       "      <td>356.980011</td>\n",
       "      <td>353.450012</td>\n",
       "      <td>354.829987</td>\n",
       "      <td>354.453918</td>\n",
       "      <td>9898600</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>2023-12-27T00:00:00.000</td>\n",
       "      <td>356.070007</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>355.309998</td>\n",
       "      <td>357.829987</td>\n",
       "      <td>357.450714</td>\n",
       "      <td>13207900</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>2023-12-28T00:00:00.000</td>\n",
       "      <td>359.700012</td>\n",
       "      <td>361.899994</td>\n",
       "      <td>357.809998</td>\n",
       "      <td>358.320007</td>\n",
       "      <td>357.940216</td>\n",
       "      <td>11798800</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>2023-12-29T00:00:00.000</td>\n",
       "      <td>358.989990</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>351.820007</td>\n",
       "      <td>353.959991</td>\n",
       "      <td>353.584839</td>\n",
       "      <td>14980500</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date        Open        High         Low       Close  \\\n",
       "3760  2023-12-22T00:00:00.000  355.579987  357.200012  351.220001  353.390015   \n",
       "3761  2023-12-26T00:00:00.000  354.989990  356.980011  353.450012  354.829987   \n",
       "3762  2023-12-27T00:00:00.000  356.070007  359.000000  355.309998  357.829987   \n",
       "3763  2023-12-28T00:00:00.000  359.700012  361.899994  357.809998  358.320007   \n",
       "3764  2023-12-29T00:00:00.000  358.989990  360.000000  351.820007  353.959991   \n",
       "\n",
       "       Adj Close    Volume company  \n",
       "3760  353.015472  11764200    META  \n",
       "3761  354.453918   9898600    META  \n",
       "3762  357.450714  13207900    META  \n",
       "3763  357.940216  11798800    META  \n",
       "3764  353.584839  14980500    META  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bda47821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there is any duplication\n",
    "df_sp.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e90c66b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "company      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there is any missing value\n",
    "df_sp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7416c26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "company      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "285fcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format date\n",
    "from datetime import datetime\n",
    "\n",
    "# covert to datetime\n",
    "df_sp['Date'] = pd.to_datetime(df_sp['Date'])\n",
    "\n",
    "# date in MM-DD-YYYY format\n",
    "df_sp['Date'] = df_sp['Date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c63a782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>company</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>133.610001</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>126.830078</td>\n",
       "      <td>143301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>128.398163</td>\n",
       "      <td>97664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>127.720001</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>124.076096</td>\n",
       "      <td>155088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>128.360001</td>\n",
       "      <td>131.630005</td>\n",
       "      <td>127.860001</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>128.309982</td>\n",
       "      <td>109578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>129.417465</td>\n",
       "      <td>105158200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>META</td>\n",
       "      <td>355.579987</td>\n",
       "      <td>357.200012</td>\n",
       "      <td>351.220001</td>\n",
       "      <td>353.390015</td>\n",
       "      <td>353.015472</td>\n",
       "      <td>11764200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>META</td>\n",
       "      <td>354.989990</td>\n",
       "      <td>356.980011</td>\n",
       "      <td>353.450012</td>\n",
       "      <td>354.829987</td>\n",
       "      <td>354.453918</td>\n",
       "      <td>9898600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>META</td>\n",
       "      <td>356.070007</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>355.309998</td>\n",
       "      <td>357.829987</td>\n",
       "      <td>357.450714</td>\n",
       "      <td>13207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>META</td>\n",
       "      <td>359.700012</td>\n",
       "      <td>361.899994</td>\n",
       "      <td>357.809998</td>\n",
       "      <td>358.320007</td>\n",
       "      <td>357.940216</td>\n",
       "      <td>11798800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>META</td>\n",
       "      <td>358.989990</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>351.820007</td>\n",
       "      <td>353.959991</td>\n",
       "      <td>353.584839</td>\n",
       "      <td>14980500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3765 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date company        Open        High         Low       Close  \\\n",
       "0     2021-01-04    AAPL  133.520004  133.610001  126.760002  129.410004   \n",
       "1     2021-01-05    AAPL  128.889999  131.740005  128.429993  131.009995   \n",
       "2     2021-01-06    AAPL  127.720001  131.050003  126.379997  126.599998   \n",
       "3     2021-01-07    AAPL  128.360001  131.630005  127.860001  130.919998   \n",
       "4     2021-01-08    AAPL  132.429993  132.630005  130.229996  132.050003   \n",
       "...          ...     ...         ...         ...         ...         ...   \n",
       "3760  2023-12-22    META  355.579987  357.200012  351.220001  353.390015   \n",
       "3761  2023-12-26    META  354.989990  356.980011  353.450012  354.829987   \n",
       "3762  2023-12-27    META  356.070007  359.000000  355.309998  357.829987   \n",
       "3763  2023-12-28    META  359.700012  361.899994  357.809998  358.320007   \n",
       "3764  2023-12-29    META  358.989990  360.000000  351.820007  353.959991   \n",
       "\n",
       "       Adj Close     Volume  \n",
       "0     126.830078  143301900  \n",
       "1     128.398163   97664900  \n",
       "2     124.076096  155088000  \n",
       "3     128.309982  109578200  \n",
       "4     129.417465  105158200  \n",
       "...          ...        ...  \n",
       "3760  353.015472   11764200  \n",
       "3761  354.453918    9898600  \n",
       "3762  357.450714   13207900  \n",
       "3763  357.940216   11798800  \n",
       "3764  353.584839   14980500  \n",
       "\n",
       "[3765 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp = df_sp.iloc[:,[0, 7, 1, 2, 3, 4, 5, 6]]\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89de7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.to_csv('Stock_Prices.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd007f",
   "metadata": {},
   "source": [
    "## Data Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d56b06",
   "metadata": {},
   "source": [
    "Label sentiment score of each financial news based on Loughran and McDonald Financial Sentiment Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f79cf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysentiment2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pysentiment2) (2.2.2)\n",
      "Requirement already satisfied: nltk>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pysentiment2) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=2.0->pysentiment2) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=2.0->pysentiment2) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=2.0->pysentiment2) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from nltk>=2.0->pysentiment2) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas->pysentiment2) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas->pysentiment2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas->pysentiment2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas->pysentiment2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->pysentiment2) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from click->nltk>=2.0->pysentiment2) (0.4.6)\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pysentiment2\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "193960a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published date</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple (AAPL) to Report Q1 Earnings: What's in ...</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiS2h0d...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>How to Trade Apple (AAPL) in the First Half of...</td>\n",
       "      <td>Investopedia</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiUWh0d...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>What Facebook (FB), Twitter (TWTR), Apple (AAP...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMidGh0d...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-24</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL After Hours: Share Price Slides On Tech W...</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSmh0d...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple reports blowout quarter, booking more th...</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiQGh0d...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>2023-11-29</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta Quest 3: The Holiday Gift That Transforms...</td>\n",
       "      <td>Meta</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiVmh0d...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>META</td>\n",
       "      <td>noyb files GDPR complaint against Meta over “P...</td>\n",
       "      <td>NOYB</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSmh0d...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>META</td>\n",
       "      <td>Two years later, Facebook's rebrand as Meta lo...</td>\n",
       "      <td>Fast Company</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiS2h0d...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta smart glasses—large language models and t...</td>\n",
       "      <td>Nature.com</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiMmh0d...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta-reinforcement learning via orbitofrontal ...</td>\n",
       "      <td>Nature.com</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiMmh0d...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4612 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     published date company  \\\n",
       "0        2021-01-22    AAPL   \n",
       "1        2021-01-07    AAPL   \n",
       "2        2021-02-08    AAPL   \n",
       "3        2021-03-24    AAPL   \n",
       "4        2021-01-27    AAPL   \n",
       "...             ...     ...   \n",
       "4617     2023-11-29    META   \n",
       "4618     2023-11-28    META   \n",
       "4619     2023-10-28    META   \n",
       "4620     2023-12-04    META   \n",
       "4621     2023-11-13    META   \n",
       "\n",
       "                                                  title      publisher  \\\n",
       "0     Apple (AAPL) to Report Q1 Earnings: What's in ...  Yahoo Finance   \n",
       "1     How to Trade Apple (AAPL) in the First Half of...   Investopedia   \n",
       "2     What Facebook (FB), Twitter (TWTR), Apple (AAP...      Bloomberg   \n",
       "3     AAPL After Hours: Share Price Slides On Tech W...      TheStreet   \n",
       "4     Apple reports blowout quarter, booking more th...           CNBC   \n",
       "...                                                 ...            ...   \n",
       "4617  Meta Quest 3: The Holiday Gift That Transforms...           Meta   \n",
       "4618  noyb files GDPR complaint against Meta over “P...           NOYB   \n",
       "4619  Two years later, Facebook's rebrand as Meta lo...   Fast Company   \n",
       "4620  Meta smart glasses—large language models and t...     Nature.com   \n",
       "4621  Meta-reinforcement learning via orbitofrontal ...     Nature.com   \n",
       "\n",
       "                                                    url sentiment_score  \n",
       "0     https://news.google.com/rss/articles/CBMiS2h0d...         Neutral  \n",
       "1     https://news.google.com/rss/articles/CBMiUWh0d...         Neutral  \n",
       "2     https://news.google.com/rss/articles/CBMidGh0d...         Neutral  \n",
       "3     https://news.google.com/rss/articles/CBMiSmh0d...        Negative  \n",
       "4     https://news.google.com/rss/articles/CBMiQGh0d...         Neutral  \n",
       "...                                                 ...             ...  \n",
       "4617  https://news.google.com/rss/articles/CBMiVmh0d...        Positive  \n",
       "4618  https://news.google.com/rss/articles/CBMiSmh0d...        Negative  \n",
       "4619  https://news.google.com/rss/articles/CBMiS2h0d...         Neutral  \n",
       "4620  https://news.google.com/rss/articles/CBMiMmh0d...        Positive  \n",
       "4621  https://news.google.com/rss/articles/CBMiMmh0d...         Neutral  \n",
       "\n",
       "[4612 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def get_sentiment_score(title):\n",
    " \n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    sentiment_score = sid_obj.polarity_scores(title)\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_score['compound'] >= 0.05 :\n",
    "        return \"Positive\"\n",
    " \n",
    "    elif sentiment_score['compound'] <= - 0.05 :\n",
    "        return \"Negative\"\n",
    " \n",
    "    else :\n",
    "        return \"Neutral\"\n",
    "    \n",
    "df_fn['sentiment_score'] = df_fn['title'].apply(get_sentiment_score)\n",
    "df_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "067c2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pysentiment2 as ps\n",
    "\n",
    "# lm = ps.LM()\n",
    "\n",
    "# def get_sentiment_score(title):\n",
    "#     tokens = lm.tokenize(title)\n",
    "#     score = lm.get_score(tokens)\n",
    "#     return score\n",
    "\n",
    "# df_fn['sentiment_score'] = df_fn['title'].apply(get_sentiment_score)\n",
    "# df_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d82ba6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter whether it is positive, negative or neutral sentiments\n",
    "\n",
    "# df_fn['sentiment_score'] = pd.Series(df_fn['sentiment_score'], dtype=\"string\")\n",
    "\n",
    "# def extract_sentiment(sentiment_string):\n",
    "#     try:\n",
    "#         # Convert string to dictionary\n",
    "#         dict_obj = ast.literal_eval(sentiment_string)\n",
    "        \n",
    "#         # Extract the sentiment\n",
    "#         positive = dict_obj.get('Positive')\n",
    "#         negative = dict_obj.get('Negative')\n",
    "        \n",
    "#         if positive != 0:\n",
    "#             return 'positive'\n",
    "#         elif negative != 0:\n",
    "#             return 'negative'\n",
    "#         else:\n",
    "#             return 'neutral'\n",
    "    \n",
    "#     except (ValueError, SyntaxError):\n",
    "#         return None\n",
    "    \n",
    "# df_fn['sentiment_score'] = df_fn['sentiment_score'].apply(extract_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a23df10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published date</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple (AAPL) to Report Q1 Earnings: What's in ...</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiS2h0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>How to Trade Apple (AAPL) in the First Half of...</td>\n",
       "      <td>Investopedia</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiUWh0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>What Facebook (FB), Twitter (TWTR), Apple (AAP...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMidGh0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-24</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL After Hours: Share Price Slides On Tech W...</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSmh0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple reports blowout quarter, booking more th...</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiQGh0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>2023-11-29</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta Quest 3: The Holiday Gift That Transforms...</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiVmh0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>META</td>\n",
       "      <td>noyb files GDPR complaint against Meta over “P...</td>\n",
       "      <td>NOYB</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSmh0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>META</td>\n",
       "      <td>Two years later, Facebook's rebrand as Meta lo...</td>\n",
       "      <td>Fast Company</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiS2h0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta smart glasses—large language models and t...</td>\n",
       "      <td>Nature.com</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiMmh0d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>META</td>\n",
       "      <td>Meta-reinforcement learning via orbitofrontal ...</td>\n",
       "      <td>Nature.com</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiMmh0d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4612 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     published date company  \\\n",
       "0        2021-01-22    AAPL   \n",
       "1        2021-01-07    AAPL   \n",
       "2        2021-02-08    AAPL   \n",
       "3        2021-03-24    AAPL   \n",
       "4        2021-01-27    AAPL   \n",
       "...             ...     ...   \n",
       "4617     2023-11-29    META   \n",
       "4618     2023-11-28    META   \n",
       "4619     2023-10-28    META   \n",
       "4620     2023-12-04    META   \n",
       "4621     2023-11-13    META   \n",
       "\n",
       "                                                  title      publisher  \\\n",
       "0     Apple (AAPL) to Report Q1 Earnings: What's in ...  Yahoo Finance   \n",
       "1     How to Trade Apple (AAPL) in the First Half of...   Investopedia   \n",
       "2     What Facebook (FB), Twitter (TWTR), Apple (AAP...      Bloomberg   \n",
       "3     AAPL After Hours: Share Price Slides On Tech W...      TheStreet   \n",
       "4     Apple reports blowout quarter, booking more th...           CNBC   \n",
       "...                                                 ...            ...   \n",
       "4617  Meta Quest 3: The Holiday Gift That Transforms...           Meta   \n",
       "4618  noyb files GDPR complaint against Meta over “P...           NOYB   \n",
       "4619  Two years later, Facebook's rebrand as Meta lo...   Fast Company   \n",
       "4620  Meta smart glasses—large language models and t...     Nature.com   \n",
       "4621  Meta-reinforcement learning via orbitofrontal ...     Nature.com   \n",
       "\n",
       "     sentiment_score                                                url  \n",
       "0            Neutral  https://news.google.com/rss/articles/CBMiS2h0d...  \n",
       "1            Neutral  https://news.google.com/rss/articles/CBMiUWh0d...  \n",
       "2            Neutral  https://news.google.com/rss/articles/CBMidGh0d...  \n",
       "3           Negative  https://news.google.com/rss/articles/CBMiSmh0d...  \n",
       "4            Neutral  https://news.google.com/rss/articles/CBMiQGh0d...  \n",
       "...              ...                                                ...  \n",
       "4617        Positive  https://news.google.com/rss/articles/CBMiVmh0d...  \n",
       "4618        Negative  https://news.google.com/rss/articles/CBMiSmh0d...  \n",
       "4619         Neutral  https://news.google.com/rss/articles/CBMiS2h0d...  \n",
       "4620        Positive  https://news.google.com/rss/articles/CBMiMmh0d...  \n",
       "4621         Neutral  https://news.google.com/rss/articles/CBMiMmh0d...  \n",
       "\n",
       "[4612 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fn = df_fn.iloc[:,[0, 1, 2, 3, 5, 4]]\n",
    "df_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1a2b0c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fn.to_csv('Financial_News.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da5d134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change delimiter for importing dataset into MySQL\n",
    "# FinancialNews.csv is for MySQL\n",
    "\n",
    "import csv\n",
    "\n",
    "input_file = 'Financial_News.csv'  # Replace with your input CSV file name\n",
    "output_file = 'FinancialNews.csv'  # Replace with your desired output CSV file name\n",
    "\n",
    "def add_quotes(value):\n",
    "    return f'{value}'\n",
    "\n",
    "with open(input_file, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    reader = csv.reader(infile)\n",
    "    header = next(reader)  # Read the header row\n",
    "    writer = csv.writer(outfile, delimiter='*', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for row in reader:\n",
    "        cleaned_row = [col.strip() for col in row if col.strip() != '']  # Remove empty columns\n",
    "        writer.writerow(cleaned_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9df4fe",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "831ee48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.18.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip setuptools\n",
    "# !pip install transformers --ignore-installed TBB\n",
    "# !python -m venv myenv\n",
    "# !myenv\\Scripts\\activate\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f8f0e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\asus\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.6/12.8 MB 5.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 9.5 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/12.8 MB 10.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.9/12.8 MB 11.4 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 12.8 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.4/12.8 MB 13.5 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.0/12.8 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.1/12.8 MB 13.8 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 7.0/12.8 MB 14.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.8/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 15.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.2/12.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.5/12.8 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.5/12.8 MB 16.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.5/12.8 MB 13.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.2/12.8 MB 13.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.3/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\asus\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.42.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbe3ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to download the stopwords dataset in order to import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08a28ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_25572\\3021827399.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fn.loc[:, 'cleaned_title'] = df_fn.loc[:,'title'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(title):\n",
    "    \n",
    "    title = title.lower() # Convert to lowercase\n",
    "\n",
    "    # Remove punctuation\n",
    "    title = title.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize and lemmatize\n",
    "    doc = nlp(title)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_fn.loc[:, 'cleaned_title'] = df_fn.loc[:,'title'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76c6e76c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_25572\\1932396384.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fn.loc[:,'label'] = df_fn.loc[:,'sentiment_score'].map(label_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Map labels to integers\n",
    "label_mapping = {'Neutral': 0, 'Negative': 1, 'Positive': 2}\n",
    "df_fn.loc[:,'label'] = df_fn.loc[:,'sentiment_score'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9a88605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published date</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>url</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>META</td>\n",
       "      <td>From ATOM to GradiATOM: Cortical gradients sup...</td>\n",
       "      <td>ScienceDirect.com</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiQ2h0d...</td>\n",
       "      <td>atom gradiatom cortical gradient support time ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>META</td>\n",
       "      <td>A global meta-analysis of greenhouse gases emi...</td>\n",
       "      <td>ScienceDirect.com</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiQ2h0d...</td>\n",
       "      <td>global metaanalysis greenhouse gas emission cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla reports 499,550 vehicle deliveries for 2...</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiX2h0d...</td>\n",
       "      <td>tesla report 499550 vehicle delivery 2020 slig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla (TSLA) Breaks Out After Beating Delivery...</td>\n",
       "      <td>Investopedia</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiWWh0d...</td>\n",
       "      <td>tesla tsla break beat delivery target   invest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>META</td>\n",
       "      <td>Differential and spatial expression meta-analy...</td>\n",
       "      <td>Nature.com</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiMmh0d...</td>\n",
       "      <td>differential spatial expression metaanalysis g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla Forecast: Why 2024 Will Be Decisive for ...</td>\n",
       "      <td>InvestorPlace</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiWmh0d...</td>\n",
       "      <td>tesla forecast 2024 decisive tsla stock   inve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3 Reasons Why Amazon (AMZN) Is a Great Growth ...</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiR2h0d...</td>\n",
       "      <td>3 reason amazon amzn great growth stock   yaho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Is It Too Late to Buy Microsoft? - The Motley ...</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSmh0d...</td>\n",
       "      <td>late buy microsoft   motley fool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Should You Buy Amazon Stock in 2024? - The Mot...</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiTmh0d...</td>\n",
       "      <td>buy amazon stock 2024   motley fool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4259</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Stock: Get Ready for a Strong 2024, Says...</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiS2h0d...</td>\n",
       "      <td>apple stock get ready strong 2024 say dan ive ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4612 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     published date company  \\\n",
       "358      2021-01-01    META   \n",
       "346      2021-01-01    META   \n",
       "162      2021-01-02    TSLA   \n",
       "143      2021-01-04    TSLA   \n",
       "363      2021-01-04    META   \n",
       "...             ...     ...   \n",
       "4402     2023-12-28    TSLA   \n",
       "4307     2023-12-29    AMZN   \n",
       "4530     2023-12-29    MSFT   \n",
       "4315     2023-12-29    AMZN   \n",
       "4259     2023-12-31    AAPL   \n",
       "\n",
       "                                                  title          publisher  \\\n",
       "358   From ATOM to GradiATOM: Cortical gradients sup...  ScienceDirect.com   \n",
       "346   A global meta-analysis of greenhouse gases emi...  ScienceDirect.com   \n",
       "162   Tesla reports 499,550 vehicle deliveries for 2...               CNBC   \n",
       "143   Tesla (TSLA) Breaks Out After Beating Delivery...       Investopedia   \n",
       "363   Differential and spatial expression meta-analy...         Nature.com   \n",
       "...                                                 ...                ...   \n",
       "4402  Tesla Forecast: Why 2024 Will Be Decisive for ...      InvestorPlace   \n",
       "4307  3 Reasons Why Amazon (AMZN) Is a Great Growth ...      Yahoo Finance   \n",
       "4530  Is It Too Late to Buy Microsoft? - The Motley ...    The Motley Fool   \n",
       "4315  Should You Buy Amazon Stock in 2024? - The Mot...    The Motley Fool   \n",
       "4259  Apple Stock: Get Ready for a Strong 2024, Says...      Yahoo Finance   \n",
       "\n",
       "     sentiment_score                                                url  \\\n",
       "358         Positive  https://news.google.com/rss/articles/CBMiQ2h0d...   \n",
       "346          Neutral  https://news.google.com/rss/articles/CBMiQ2h0d...   \n",
       "162         Negative  https://news.google.com/rss/articles/CBMiX2h0d...   \n",
       "143         Negative  https://news.google.com/rss/articles/CBMiWWh0d...   \n",
       "363         Negative  https://news.google.com/rss/articles/CBMiMmh0d...   \n",
       "...              ...                                                ...   \n",
       "4402        Positive  https://news.google.com/rss/articles/CBMiWmh0d...   \n",
       "4307        Positive  https://news.google.com/rss/articles/CBMiR2h0d...   \n",
       "4530        Negative  https://news.google.com/rss/articles/CBMiSmh0d...   \n",
       "4315        Negative  https://news.google.com/rss/articles/CBMiTmh0d...   \n",
       "4259        Positive  https://news.google.com/rss/articles/CBMiS2h0d...   \n",
       "\n",
       "                                          cleaned_title  label  \n",
       "358   atom gradiatom cortical gradient support time ...      2  \n",
       "346   global metaanalysis greenhouse gas emission cr...      0  \n",
       "162   tesla report 499550 vehicle delivery 2020 slig...      1  \n",
       "143   tesla tsla break beat delivery target   invest...      1  \n",
       "363   differential spatial expression metaanalysis g...      1  \n",
       "...                                                 ...    ...  \n",
       "4402  tesla forecast 2024 decisive tsla stock   inve...      2  \n",
       "4307  3 reason amazon amzn great growth stock   yaho...      2  \n",
       "4530                   late buy microsoft   motley fool      1  \n",
       "4315                buy amazon stock 2024   motley fool      1  \n",
       "4259  apple stock get ready strong 2024 say dan ive ...      2  \n",
       "\n",
       "[4612 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fn = df_fn.sort_values(by='published date')\n",
    "df_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cba3e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff37dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize and encode the data using the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "df_fn['tokenized'] = df_fn['cleaned_title'].apply(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83c60d18-fb39-493e-9b7c-8232beaae820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91618e9f-e071-4a26-a6fc-1f98b3af1ad1",
   "metadata": {},
   "source": [
    "## Splitting Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da6b0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train(70%) and test dataset(30%)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(df_fn['tokenized'].to_list(), df_fn['label'].to_list(), test_size=0.3, random_state=42)\n",
    "\n",
    "#Split the remaining 30% of test dataset into validation and test data\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0474878-dd36-46c2-813d-ec9fdadc92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dicts(tokenized_texts):\n",
    "    input_ids = [d['input_ids'] for d in tokenized_texts]\n",
    "    attention_masks = [d['attention_mask'] for d in tokenized_texts]\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_masks}\n",
    "\n",
    "# Convert to lists of dictionaries\n",
    "train_encodings = convert_to_dicts(x_train)\n",
    "val_encodings = convert_to_dicts(x_val)\n",
    "test_encodings = convert_to_dicts(x_test)\n",
    "\n",
    "# Create three dataset objects using the SentimentDataset\n",
    "train_dataset = SentimentDataset(train_encodings, y_train)\n",
    "val_dataset = SentimentDataset(val_encodings, y_val)\n",
    "test_dataset = SentimentDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038acd50",
   "metadata": {},
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e31c768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#BERT Model\n",
    "model_BERT= BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1bd0524e-b0ca-4db0-88b7-f52b95ae1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\asus\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from accelerate) (2.3.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47fdaee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', # All files generated during training will be stored here\n",
    "    num_train_epochs=3, # The model will be trained for 3 full epochs unless the step limit (max_steps) is reached first\n",
    "    per_device_train_batch_size=5, # Training batch size per device (GPU or CPU).\n",
    "    per_device_eval_batch_size=5, # Evaluation batch size per device (GPU or CPU).\n",
    "    warmup_steps=10, # Number of warm-up steps during which the learning rate gradually increases to its initial value\n",
    "    weight_decay=0.01, # Weight decay rate: this technique helps to avoid overfitting, penalizing large weights in the neural network\n",
    "    logging_dir='./logs', # Directory where training logs will be stored\n",
    "    max_steps=10,  # Maximum number of training steps to be performed\n",
    "    save_steps=2,  # Range of steps after which the model will be saved\n",
    "    logging_steps=2,  # Range of steps after which log information will be recorded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b83e18a7-0efb-4e78-ae1a-54ba661d8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7c28ab7-b08e-45fc-8fa7-c02c70c26bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(p):\n",
    "#     preds = p.predictions.argmax(-1)\n",
    "#     return precision_recall_fscore_support(p.label_ids, preds, average='binary', zero_division=0)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66f4c04a-560e-49c7-b266-2194f948acff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.167700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.034100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=1.1044312953948974, metrics={'train_runtime': 62.4698, 'train_samples_per_second': 0.8, 'train_steps_per_second': 0.16, 'total_flos': 3288917721600.0, 'train_loss': 1.1044312953948974, 'epoch': 0.015479876160990712})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_bert = Trainer(\n",
    "    model=model_BERT, # The pre-trained model that you want to fine-tune or train\n",
    "    args=training_args, # The training arguments that specify the configurations for the training process\n",
    "    train_dataset=train_dataset, # The dataset used for training the model\n",
    "    eval_dataset=val_dataset # The dataset used for evaluating the model during training\n",
    "    # compute_metrics=compute_metrics # custom metrics function\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer_bert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "519ac19f-9f41-406d-be66-0d08d0571785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinBERT model\n",
    "model_FinBERT = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "tokeniezer_finbert=  BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0f074d5-a079-452e-9bb3-7dcb75049ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_finbert = pipeline('sentiment-analysis', model=finbert, tokenizer=tokenizer_finbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be0c22ce-0aa5-43dc-811d-8f2bc9ce789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.634100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.988600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.647600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.248900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=4.250070285797119, metrics={'train_runtime': 61.304, 'train_samples_per_second': 0.816, 'train_steps_per_second': 0.163, 'total_flos': 3288917721600.0, 'train_loss': 4.250070285797119, 'epoch': 0.015479876160990712})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_finbert = Trainer(\n",
    "    model=model_FinBERT, # The pre-trained model that you want to fine-tune or train\n",
    "    args=training_args, # The training arguments that specify the configurations for the training process\n",
    "    train_dataset=train_dataset, # The dataset used for training the model\n",
    "    eval_dataset=val_dataset # The dataset used for evaluating the model during training\n",
    "    # compute_metrics=compute_metrics # custom metrics function\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer_finbert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af500ed7-fe88-4f71-a882-da68e7bcca35",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab86ba2f-9717-4508-ac47-1ebce0cb3c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "***** BERT model*****\n",
      "  - Loss: 1.0728\n",
      "  - Runtime: 240.51 seconds\n",
      "  - Samples per Second: 2.88\n",
      "  - Steps per Second: 0.58\n",
      "  - Epoch: 0.0155\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** FinBERT model*****\n",
      "  - Loss: 3.4681\n",
      "  - Runtime: 231.19 seconds\n",
      "  - Samples per Second: 2.99\n",
      "  - Steps per Second: 0.60\n",
      "  - Epoch: 0.0155\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "results_bert = trainer_bert.evaluate(test_dataset)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print('***** BERT model*****')\n",
    "print(f\"  - Loss: {results_bert['eval_loss']:.4f}\")\n",
    "print(f\"  - Runtime: {results_bert['eval_runtime']:.2f} seconds\")\n",
    "print(f\"  - Samples per Second: {results_bert['eval_samples_per_second']:.2f}\")\n",
    "print(f\"  - Steps per Second: {results_bert['eval_steps_per_second']:.2f}\")\n",
    "print(f\"  - Epoch: {results_bert['epoch']:.4f}\")\n",
    "# print(f\"  - Accuracy: {results_bert['eval_accuracy']:.4f}\")\n",
    "# print(f\"  - F1: {results_bert['f1']:.4f}\")\n",
    "# print(f\"  - Recall: {results_bert['recall']:.4f}\")\n",
    "# print(f\"  - Precision: {results_bert['precision']:.4f}\")\n",
    "\n",
    "results_finbert = trainer_finbert.evaluate(test_dataset)\n",
    "print('\\n')\n",
    "print('***** FinBERT model*****')\n",
    "print(f\"  - Loss: {results_finbert['eval_loss']:.4f}\")\n",
    "print(f\"  - Runtime: {results_finbert['eval_runtime']:.2f} seconds\")\n",
    "print(f\"  - Samples per Second: {results_finbert['eval_samples_per_second']:.2f}\")\n",
    "print(f\"  - Steps per Second: {results_finbert['eval_steps_per_second']:.2f}\")\n",
    "print(f\"  - Epoch: {results_finbert['epoch']:.4f}\")\n",
    "# print(f\"  - Accuracy: {results_bert['eval_accuracy']:.4f}\")\n",
    "# print(f\"  - F1: {results_bert['f1']:.4f}\")\n",
    "# print(f\"  - Recall: {results_bert['recall']:.4f}\")\n",
    "# print(f\"  - Precision: {results_bert['precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e97541-8f54-4bfc-9663-179bb7363781",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18dbec5b-edf3-4c99-8c05-4c03d334caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment_BERT(text):\n",
    "    '''Function to predict the sentiment of a given text using a pre-trained BERT model.\n",
    "    Args: the input text for sentiment prediction.\n",
    "    Returns: the predicted sentiment ('negative', 'neutral', 'positive').\n",
    "    '''\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    outputs = model_BERT(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "    sentiment = {0: 'Neutral', 1: 'Negative', 2: 'Positive'}\n",
    "    return sentiment[predicted_class]\n",
    "\n",
    "# Example prediction\n",
    "example_text = \"Apple (AAPL) Traded Higher After Its AI Strategy Announcement\"\n",
    "predicted_sentiment = predict_sentiment_BERT(example_text)\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1361befe-fe0a-4c56-8399-6d5ee555cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "799e2dac-dd8a-45fa-aa0d-3d6a667a32a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.02485509, -0.14145346, -0.10871138],\n",
      "       [ 0.00308365, -0.41551214, -0.16578211],\n",
      "       [-0.02785653, -0.28455245, -0.16185603],\n",
      "       ...,\n",
      "       [-0.16026694, -0.18797064, -0.16198884],\n",
      "       [ 0.15245312, -0.4016062 , -0.23979338],\n",
      "       [ 0.08986136, -0.38363174, -0.18223488]], dtype=float32), label_ids=array([2, 0, 1, 0, 2, 0, 0, 2, 2, 0, 1, 2, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0,\n",
      "       0, 2, 1, 1, 0, 0, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 0,\n",
      "       2, 0, 2, 2, 2, 1, 2, 1, 0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2,\n",
      "       0, 1, 0, 1, 0, 2, 0, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0,\n",
      "       2, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 0, 2, 2, 2, 1, 0,\n",
      "       2, 2, 2, 2, 0, 2, 0, 2, 1, 0, 0, 2, 1, 0, 1, 0, 0, 2, 0, 2, 0, 2,\n",
      "       0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 1, 0, 2, 1, 1,\n",
      "       2, 1, 0, 0, 1, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 1, 0, 2, 2,\n",
      "       0, 2, 0, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 1, 2, 1, 0, 2, 0, 0, 2,\n",
      "       0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 1, 1, 2, 2, 2,\n",
      "       2, 1, 2, 2, 2, 1, 1, 1, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 0, 0, 2,\n",
      "       1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 2, 2,\n",
      "       2, 0, 2, 0, 2, 1, 2, 2, 0, 1, 0, 2, 2, 2, 0, 0, 1, 0, 2, 2, 0, 2,\n",
      "       1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
      "       0, 1, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 0,\n",
      "       1, 0, 0, 2, 1, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0, 2, 0, 0, 2, 2, 0, 0,\n",
      "       1, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 0, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0,\n",
      "       2, 2, 0, 1, 0, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 2, 0, 0, 2, 2, 2,\n",
      "       2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2, 2, 1, 2, 2, 2, 0, 0, 2, 1,\n",
      "       2, 2, 2, 2, 2, 1, 0, 0, 1, 2, 2, 0, 2, 2, 1, 0, 0, 1, 0, 1, 2, 2,\n",
      "       0, 0, 1, 0, 2, 1, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 2, 2, 1,\n",
      "       2, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2,\n",
      "       0, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 1, 2, 1, 0,\n",
      "       0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 2,\n",
      "       0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2,\n",
      "       0, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1,\n",
      "       0, 0, 2, 1, 2, 2, 2, 0, 1, 2, 0, 0, 2, 1, 1, 2, 1, 1, 2, 0, 1, 1,\n",
      "       2, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 2, 0, 1, 2, 0, 2, 0,\n",
      "       0, 0, 2, 2, 1, 2, 0, 2, 1, 2], dtype=int64), metrics={'test_loss': 1.072820782661438, 'test_runtime': 358.7454, 'test_samples_per_second': 1.929, 'test_steps_per_second': 0.387})\n"
     ]
    }
   ],
   "source": [
    "# y_pred_bert = df_fn['title'].apply(predict_sentiment_BERT)\n",
    "y_pred_bert = trainer_bert.predict(test_dataset)\n",
    "print(y_pred_bert)\n",
    "# comparison_df_bert = pd.DataFrame({'Actual Sentiment': y_test, 'Predicted Sentiment': y_pred_bert})\n",
    "# print(comparison_df_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6c3d08a-4510-440e-9039-508abb3c826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39\n",
      "Precision: 0.40\n",
      "Recall: 0.34\n",
      "F1 Score: 0.23\n"
     ]
    }
   ],
   "source": [
    "y_pred_bert = np.argmax(y_pred_bert.predictions, axis=-1) \n",
    "y_test_array = np.array(y_test)  # Ensure y_test is a numpy array for comparison\n",
    "y_pred_bert_array = np.array(y_pred_bert)\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_array, y_pred_bert_array)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test_array, y_pred_bert_array, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test_array, y_pred_bert_array, average='macro')\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test_array, y_pred_bert_array, average='macro')\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3ee56d8-a43b-4daa-9d79-447e66c09e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-4.384128  ,  3.2145245 ,  4.8502445 ],\n",
      "       [-0.1293976 , -1.2346987 ,  3.0320313 ],\n",
      "       [-1.4541361 ,  0.1105828 ,  4.7190027 ],\n",
      "       ...,\n",
      "       [-2.0768683 , -0.13518861,  5.0314827 ],\n",
      "       [-1.7531585 ,  0.22667807,  5.0115347 ],\n",
      "       [ 0.09588408, -1.4778402 ,  4.3294544 ]], dtype=float32), label_ids=array([2, 0, 1, 0, 2, 0, 0, 2, 2, 0, 1, 2, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0,\n",
      "       0, 2, 1, 1, 0, 0, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 0,\n",
      "       2, 0, 2, 2, 2, 1, 2, 1, 0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2,\n",
      "       0, 1, 0, 1, 0, 2, 0, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0,\n",
      "       2, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 0, 2, 2, 2, 1, 0,\n",
      "       2, 2, 2, 2, 0, 2, 0, 2, 1, 0, 0, 2, 1, 0, 1, 0, 0, 2, 0, 2, 0, 2,\n",
      "       0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 1, 0, 2, 1, 1,\n",
      "       2, 1, 0, 0, 1, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 1, 0, 2, 2,\n",
      "       0, 2, 0, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 1, 2, 1, 0, 2, 0, 0, 2,\n",
      "       0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 1, 1, 2, 2, 2,\n",
      "       2, 1, 2, 2, 2, 1, 1, 1, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 0, 0, 2,\n",
      "       1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 2, 2,\n",
      "       2, 0, 2, 0, 2, 1, 2, 2, 0, 1, 0, 2, 2, 2, 0, 0, 1, 0, 2, 2, 0, 2,\n",
      "       1, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
      "       0, 1, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 0,\n",
      "       1, 0, 0, 2, 1, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0, 2, 0, 0, 2, 2, 0, 0,\n",
      "       1, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 0, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0,\n",
      "       2, 2, 0, 1, 0, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 1, 1, 1, 1, 0, 2, 0, 0, 2, 2, 2,\n",
      "       2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2, 2, 1, 2, 2, 2, 0, 0, 2, 1,\n",
      "       2, 2, 2, 2, 2, 1, 0, 0, 1, 2, 2, 0, 2, 2, 1, 0, 0, 1, 0, 1, 2, 2,\n",
      "       0, 0, 1, 0, 2, 1, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 2, 2, 1,\n",
      "       2, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2,\n",
      "       0, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 1, 2, 1, 0,\n",
      "       0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 2,\n",
      "       0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2,\n",
      "       0, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1,\n",
      "       0, 0, 2, 1, 2, 2, 2, 0, 1, 2, 0, 0, 2, 1, 1, 2, 1, 1, 2, 0, 1, 1,\n",
      "       2, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 2, 0, 1, 2, 0, 2, 0,\n",
      "       0, 0, 2, 2, 1, 2, 0, 2, 1, 2], dtype=int64), metrics={'test_loss': 3.468059539794922, 'test_runtime': 343.5373, 'test_samples_per_second': 2.014, 'test_steps_per_second': 0.405})\n"
     ]
    }
   ],
   "source": [
    "# y_pred_finbert = predict_sentiment_FinBERT(df_fn['title'])\n",
    "y_pred_finbert = trainer_finbert.predict(test_dataset)\n",
    "print(y_pred_finbert)\n",
    "# comparison_df_finbert = pd.DataFrame({'Actual Sentiment': y_test, 'Predicted Sentiment': y_pred_finbert})\n",
    "# print(comparison_df_finbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "577787fb-fe78-46f4-9929-8f3a536780b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40\n",
      "Precision: 0.51\n",
      "Recall: 0.32\n",
      "F1 Score: 0.21\n"
     ]
    }
   ],
   "source": [
    "y_pred_finbert = np.argmax(y_pred_finbert.predictions, axis=-1) \n",
    "y_test_array = np.array(y_test)  # Ensure y_test is a numpy array for comparison\n",
    "y_pred_finbert_array = np.array(y_pred_finbert)\n",
    "\n",
    "accuracy = accuracy_score(y_test_array, y_pred_finbert_array)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test_array, y_pred_finbert_array, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "# # Calculate recall\n",
    "recall = recall_score(y_test_array, y_pred_finbert_array, average='macro')\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test_array, y_pred_finbert_array, average='macro')\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
